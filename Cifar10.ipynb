{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center><div style=\"direction:rtl;font-family:B Lotus, B Nazanin, Tahoma\"> بسم الله الرحمن الرحیم</div></center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center><div style=\"direction:rtl;font-family:B Lotus, B Nazanin, Tahoma\">\n",
    "Cifar10 Dataset classification using Fully connected Neural Network</div></center></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div style=\"direction:ltr;text-align:left;font-family:B Lotus, B Nazanin, Tahoma\">  Load required libraries</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"direction:ltr;text-align:left;font-family:B Lotus, B Nazanin, Tahoma\">About Cifar10 Dataset</div>\n",
    "<div style=\"direction:ltr;text-align:left;font-family:Tahoma\">\n",
    "<br>This dataset of color images in the size of 32 by 32 and in 10 different classes, including cars, trucks, horses, etc., is available in the framework of Keras and we use the same.\n",
    "<br><br>\n",
    "You can read more about this data set from the site of this data set:<br>\n",
    "</div>\n",
    "\n",
    "https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# + Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"direction:ltr;text-align:left;font-family:B Lotus, B Nazanin, Tahoma\">Take a look at the dataset ...</div>\n",
    "<div style=\"direction:ltr;text-align:left;font-family:Tahoma\">Change the index of this photo and see a few more images in this dataset.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_train[65]) # change the index '65'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# + Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div style=\"direction:ltr;text-align:left;font-family:B Lotus, B Nazanin, Tahoma\">Convert 3 channel images into grayscale</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_pictures_train = x_train.shape[0]\n",
    "number_of_pictures_test = x_test.shape[0]\n",
    "\n",
    "number_of_pictures_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_gray = []\n",
    "x_test_gray = []\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114]).astype(int)\n",
    "\n",
    "for i in range(0,number_of_pictures_train):\n",
    "    x_train_gray.append(rgb2gray(x_train[i])) # storing converted images\n",
    "\n",
    "x_train_gray = np.array(x_train_gray) # convert list to np array\n",
    "\n",
    "for i in range(0,number_of_pictures_test):\n",
    "    x_test_gray.append(rgb2gray(x_test[i]))\n",
    "\n",
    "x_test_gray = np.array(x_test_gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div style=\"direction:ltr;text-align:left;font-family:B Lotus, B Nazanin, Tahoma\">Change datatype of features to float32</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_gray = x_train_gray.astype('float32')\n",
    "x_test_gray =  x_test_gray.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div style=\"direction:ltr;text-align:left;font-family:B Lotus, B Nazanin, Tahoma\">Normalizing</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_gray /= 255\n",
    "x_test_gray /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div style=\"direction:ltr;text-align:left;font-family:B Lotus, B Nazanin, Tahoma\">Reshape features to only one dimension</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_gray = x_train_gray.reshape(number_of_pictures_train,-1) # (... , 32 , 32) ==> (...,32*32)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
